---
title: "Report Data Cleaning"
author: "Cristin Young"
date: "2025-09-17"
output:
  html_document:
    df_print: paged
  pdf_document: default
  html_notebook: default
---

This notebook cleans up demographic and discharge data, and provides clean csv's from which to do the analyses for reports.

ACTION ITEMS
[ ] make sure we filter to last follow-up time point (filter to post_time_point == ??)

[ ] nrow(dup_clients_diff_time) + nrow(dup_clients_same_time) should equal nrow(dup_clients). It doesn't -- why??

[ ] NEED to filter by client_id + assessment_date (see client_id == 3664 for example issue)
  - need to verify, is this linking assessment + intervention because they intervention was done in that time frame? 

# Read in data
```{r}
library(tidyverse)
library(janitor)
library(gt)

discharge_data <- readxl::read_xlsx("/Users/cristin/Dropbox/Data/eInsight Exports/Discharge Report Export/2025-10-09-discharge_report.xlsx", na = c("-", "", "NA", "N/A")) %>% 
  janitor::clean_names()
demographic_data <- readxl::read_xlsx("/Users/cristin/Dropbox/Data/eInsight Exports/Admin Report Exports/2025-09-17-client_demographics.xlsx", na = c("-", "", "NA", "N/A")) %>% 
  janitor::clean_names()

# discharge_data <- readxl::read_xlsx("/Users/tristan/CWS Dropbox/Tristan Burgess/CYBHI Project/Rebecca and Tristan and Cristin/EInsight Data/Exports - Raw/May13_Report_Data/Dishcharge_Report.xlsx", na = c("-", "", "NA"))
# demographic_data <- readxl::read_xlsx("/Users/tristan/CWS Dropbox/Tristan Burgess/CYBHI Project/Rebecca and Tristan and Cristin/EInsight Data/Exports - Raw/May13_Report_Data/Client_Demographics.xlsx", na = c("-", "", "NA"))

length(discharge_data$client_id)
length(demographic_data$client_id)
```

# DEMOGRAPHIC DATA - Cleaning
```{r}
# get rid of demo data
demographic_data_filtered <- demographic_data %>%
  filter(!if_any(c(provider_id, client_id), ~ str_detect(as.character(.x), "DEMO")))

# are there unique client IDs? 
length(unique(demographic_data_filtered$client_id)) == nrow(demographic_data_filtered)

# which IDs have been repeated and how many times? 
duplicates <- demographic_data_filtered %>% 
  group_by(client_id) %>% 
   filter(n() > 1) %>%
  tally() 

# how many rows are duplicated?
duplicates %>% 
  summarise(total_duplicated = sum(n))

# what data is repeating for each client?
# appears to just be language selected? 
demographic_data_filtered %>%
  group_by(client_id) %>%
  filter(n() > 1) %>%
  summarise(across(everything(), ~ {
    u <- unique(.x)
    if(length(u) > 1) paste(u, collapse = ", ") else NA_character_
  }), .groups = "drop") %>%
  select(client_id, where(~ any(!is.na(.))))

duplicate_list <- demographic_data_filtered %>% 
  filter(client_id %in% duplicates$client_id)

write_csv(duplicate_list, "/Users/cristin/Dropbox/Rebecca and Tristan and Cristin/EInsight Data/demographic_duplicate_list.csv")

#for now, drop the 45 clients (164 rows)
demographic_data_filtered <- demographic_data_filtered %>% 
  filter(!(client_id %in% duplicates$client_id))

#check again for duplicate ids, just in case
length(unique(demographic_data_filtered$client_id)) == nrow(demographic_data_filtered)
```

## DEMOGRAPHIC DATA - Recoding race
1. Remove “don’t know”, “prefer not to answer”, and “not applicable” from the comma-separated responses.
2. Then recode the remaining responses:
- 0 if nothing is left after removal (or NA)
- 1 if exactly one valid response remains
- 2 if 2+ valid responses remain
3. do an analysis to look within race: so duplicated --> single race dummy variable
```{r}
# Define coding for single responses
codebook <- c("Asian" = 1, 
              "Black or African American" = 2, 
              "Hispanic or Latino" = 3,
              "Middle Eastern or North African" = 4,
              "Native American/American Indian or Alaska Native" = 5,
              "Native Hawaiian or Pacific Islander" = 6,
              "White" = 7
              )

demographic_data_filtered <- demographic_data_filtered %>% 
  mutate(
    # Remove "don't know", "prefer not to answer", "not applicable"
    cleaned_race = str_remove_all(
      race,
      "\\b(Don't Know|Prefer Not To Answer|Not Applicable)\\b"
    ) %>%
      str_replace_all(",+", ",") %>%        # collapse extra commas
      str_replace_all("^,|,$", "") %>%      # trim leading/trailing commas
      na_if("")                             # convert empty string to NA
  ) %>%
  mutate(
    recoded_race = case_when(
      is.na(cleaned_race) ~ 0L,             # no valid response
      str_detect(cleaned_race, ",") ~ 2L,   # multiple responses
      TRUE ~ 1L                             # single response
    ),
    # assign numeric code to single values, 99 if 2+ values
    code_num = case_when(
      is.na(cleaned_race) ~ 0L,
      str_detect(cleaned_race, ",") ~ 88L,
      TRUE ~ unname(codebook[cleaned_race])  # lookup from codebook
    )
  )
```

## DEMOGRAPHIC DATA - Recoding 
1. Remove “don’t know”, “prefer not to answer”, and “not applicable” from the comma-separated responses.
2. Then recode the remaining responses:
- 0 if nothing is left after removal (or NA)
- 1 if exactly one valid response remains
- 2 if 2+ valid responses remain
3. do an analysis to look within race: so duplicated --> single race dummy variable
```{r}
# Define coding for single responses
codebook <- c("Asian" = 1, 
              "Black or African American" = 2, 
              "Hispanic or Latino" = 3,
              "Middle Eastern or North African" = 4,
              "Native American/American Indian or Alaska Native" = 5,
              "Native Hawaiian or Pacific Islander" = 6,
              "White" = 7
              )

demographic_data_filtered <- demographic_data_filtered %>% 
  mutate(
    # Remove "don't know", "prefer not to answer", "not applicable"
    cleaned_race = str_remove_all(
      race,
      "\\b(Don't Know|Prefer Not To Answer|Not Applicable)\\b"
    ) %>%
      str_replace_all(",+", ",") %>%        # collapse extra commas
      str_replace_all("^,|,$", "") %>%      # trim leading/trailing commas
      na_if("")                             # convert empty string to NA
  ) %>%
  mutate(
    recoded_race = case_when(
      is.na(cleaned_race) ~ 0L,             # no valid response
      str_detect(cleaned_race, ",") ~ 2L,   # multiple responses
      TRUE ~ 1L                             # single response
    ),
    # assign numeric code to single values, 88 if 2+ values
    code_num = case_when(
      is.na(cleaned_race) ~ 0L,
      str_detect(cleaned_race, ",") ~ 88L,
      TRUE ~ unname(codebook[cleaned_race])  # lookup from codebook
    )
  )
```

# DISCHARGE DATA - Cleaning
```{r}
#get rid of demo data
discharge_data_filtered <- discharge_data %>%
  filter(!if_any(c(provider_id, client_id), ~ str_detect(as.character(.x), "DEMO"))) %>% 
  janitor::clean_names()

#are there unique client IDs? 
length(unique(discharge_data_filtered$client_id)) == nrow(discharge_data_filtered)

#which IDs have been repeated and how many times? 
discharge_data_filtered %>% 
  group_by(client_id) %>% 
  summarise(n=n()) %>% 
  filter(n>1)

#what data is repeating for each client?
discharge_data_filtered %>%
  group_by(client_id) %>%
  filter(n() > 1) %>%
  summarise(across(everything(), ~ {
    u <- unique(.x)
    if(length(u) > 1) paste(u, collapse = ", ") else NA_character_
  }), .groups = "drop") %>%
  select(client_id, where(~ any(!is.na(.))))

unique(discharge_data_filtered$pre_measure_s)
unique(discharge_data_filtered$post_measure_s)

#clean up pre/post-measure names
discharge_data_filtered <- discharge_data_filtered %>%
  mutate(
    pre_time_point = str_extract(
      pre_measure_s, "(Initial|(?i)follow up \\d+)"),
    pre_assessment_name = str_remove(
      pre_measure_s, "(Initial|(?i)follow up \\d+)") %>% 
      str_trim()
  ) %>% 
  mutate(
    post_time_point = str_extract(
      post_measure_s, "(Initial|(?i)follow up \\d+)"),
    post_assessment_name = str_remove(
      post_measure_s, "(Initial|(?i)follow up \\d+)") %>% 
      str_trim()
  )

#see if pre/post assessment names match yet
discharge_data_filtered <- discharge_data_filtered %>% 
mutate(MatchDistinct = pre_assessment_name == post_assessment_name)

#not everyone uses the correct name for pre vs post assessment, so clean further
discharge_data_filtered <- discharge_data_filtered %>% 
  mutate(
    trimmed_pre_assessment_name = word(pre_assessment_name, 1),
    trimmed_post_assessment_name = word(post_assessment_name, 1)
  )

#are they all the same now? 
discharge_data_filtered <- discharge_data_filtered %>% 
mutate(trimmed_match = trimmed_pre_assessment_name == trimmed_post_assessment_name)

#this is the same thing - they just wrote out SDQ for post
discharge_data_filtered %>% 
  filter(trimmed_match == FALSE)
```

# DISCHARGE DATA EDA - Look at clients with >1 intervention
```{r}
# filter to those who have a pre AND post measure
dup_client_id <- discharge_data_filtered %>%
  filter(!is.na(pre_measure_s) & !is.na(post_measure_s)) 

# create df where it shows you what was duplicated for each client ID
dup_client_id <- dup_client_id %>% 
  group_by(client_id) %>%
  filter(n() > 1) %>%
  summarise(across(everything(), ~ {
    u <- unique(.x)
    if(length(u) > 1) paste(u, collapse = ", ") else NA_character_
  }), .groups = "drop") %>%
  select(client_id, where(~ any(!is.na(.))))

#filter discharge data to only clients with duplicate rows AND ones that hove both pre and post data
dup_clients <- discharge_data_filtered %>% 
  filter(client_id %in% dup_client_id$client_id,
        !is.na(pre_measure_s) & !is.na(post_measure_s))

length(unique(dup_clients$client_id)) #338 clients with more than one complete intervention 
```

## Find clients that had >1 interventions AT THE SAME TIME
- versus clients that had more than one of the same intervention
- this does not include people who had multiple follow-ups of the same intervention; this is filtered by pre-measure name (not trimmed)
```{r}
dup_clients_same_time <- dup_clients %>% 
  group_by(client_id, intervention_start) %>% 
  summarise(across(pre_measure_s, ~ {
    u <- unique(.x)
    if(length(u) > 1) paste(u, collapse = ", ") else NA_character_
  }), .groups = "drop") %>% 
  filter(!is.na(pre_measure_s))

#this is the data for the clients that had >1 intervention at the SAME time
dup_clients_same_time_data <- discharge_data_filtered %>% 
  filter(client_id %in% dup_clients_same_time$client_id)
```

## find clients that had an intervention AT DIFFERENT TIMES
- right now this is filtering only on pre-assessment name (not trimmed)
```{r}
dup_clients_diff_time <- dup_clients %>%
  group_by(client_id) %>%
  filter(n_distinct(intervention_start, na.rm = TRUE) > 1) %>%
  summarise(
    n_intervention_start = n_distinct(intervention_start, na.rm = TRUE),
    intervention_start_dates = paste(sort(unique(intervention_start)), collapse = ", "),
    pre_measure_s_values = {
      vals <- unique(na.omit(pre_measure_s))
      if (length(vals) == 0) NA_character_
      else paste(vals, collapse = ", ")
    },
    .groups = "drop"
  )

#this is the data for the clients that had an intervention at different times
dup_clients_diff_time_data <- discharge_data_filtered %>% 
  filter(client_id %in% dup_clients_diff_time$client_id)

nrow(dup_clients_diff_time) + nrow(dup_clients_same_time)
```


# JOINING DATA 
Now join demographic and discharge data by client ID
```{r}
#assessment-level data
all_data <- left_join(discharge_data_filtered, demographic_data_filtered, by = c("client_id", "provider_id"))
head(all_data)
```

#how many unique clients were served?
```{r}
n_distinct(demographic_data_filtered$client_id)
```

#how many clients had outcomes data? 
```{r}
n_distinct(all_data$client_id)
```

#write csvs
```{r}
#all data 
# write_csv(all_data, "/Users/tristan/CWS Dropbox/Tristan Burgess/CYBHI Project/Rebecca and Tristan and Cristin/EInsight Data/demographic_discharge_clean.csv")
write_csv(all_data, "/Users/cristin/Dropbox/Rebecca and Tristan and Cristin/EInsight Data/demographic_discharge_clean.csv")

#clean demo data
# write_csv(demographic_data_filtered, "/Users/tristan/CWS Dropbox/Tristan Burgess/CYBHI Project/Rebecca and Tristan and Cristin/EInsight Data/demographic_data_clean.csv")
write_csv(demographic_data_filtered, "/Users/cristin/Dropbox/Rebecca and Tristan and Cristin/EInsight Data/demographic_data_clean.csv")

#clean dishcarge data
# write_csv(discharge_data_filtered, "/Users/tristan/CWS Dropbox/Tristan Burgess/CYBHI Project/Rebecca and Tristan and Cristin/EInsight Data/discharge_data_clean.csv")
write_csv(discharge_data_filtered, "/Users/cristin/Dropbox/Rebecca and Tristan and Cristin/EInsight Data/discharge_data_clean.csv")
```
